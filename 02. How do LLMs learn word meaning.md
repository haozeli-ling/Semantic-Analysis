## How do LLMs learn word meaning

Before diving into our computational model for meaning, let's take a quick glimpse at the algorithms behind Large Language Models (LLMs). Then, we will compare the LLM approach with the one we are going to design, so you can decide which offers a more intuitive understanding of language meaning.

### Big Question

How can a machine learn the meaning of words without a dictionary?

Although large language models can use words in remarkably fluent and appropriate ways, they do not recognize word meaning in the same way that human beings do.

- For humans, word meaning is grounded in $\color{red}{\text{perception, action, and lived experience}}$ : we learn what ''apple'' means by seeing, touching, tasting, and interacting with apples in the world.
- An LLM never perceives or interacts with the world directly. It learns entirely from $\color{red}{\text{textual patterns}}$ , discovering how words co-occur with other words across massive datasets.

As a result, an LLM’s ''understanding'' of a word consists in a statistical representation of its linguistic contexts, not in a concept tied to sensory experience, intentions, or beliefs. In this sense, LLMs model how words are used, not what words are.

### Core idea 

''The meaning of a word is its use in the language.'' --- [Ludwig Wittgenstein](https://en.wikipedia.org/wiki/Ludwig_Wittgenstein)

Let’s define the meaning of a word by its distribution in language use – its neighboring words or grammatical environments. 

> Suppose you encounter an unfamiliar word in a corpus: <br>
>
> (1) The $\color{blue}{\text{flirple}}$ barked loudly and chased mailman. <br>
> (2) A $\color{blue}{\text{flirple}}$ wagged its tail happily when its owner came home. <br>
> (3) My neighbor’s $\color{blue}{\text{flirple}}$ bit my shoe this morning. <br>
> 
> Can you guess the meaning of this word without a dictionary? 

Computers do not understand words directly; text must first be transformed into numbers that a machine can process. This approach is actually inspired by observations of human linguistic behavior. 

A classic demonstration that word meaning can be analyzed along systematic dimensions comes from [The Measurement of Meaning (1957)](https://gwern.net/doc/psychology/1957-osgood-themeasurementofmeaning.pdf) by Osgood, Suci, and Tannenbaum. Using the semantic differential method, they asked participants to rate words and concepts on pairs of opposite adjectives (such as ''good–bad'', ''strong–weak'', ''active–passive''). Their large-scale empirical studies showed that, across many languages and domains, people’s judgments of word meaning consistently clustered along three major affective dimensions: 

- Evaluation (how good or bad something is)
- Potency (how strong or weak it is), and
- Activity (how active or passive it is).

This finding suggested that, beyond dictionary definitions, words carry structured affective meanings that can be measured quantitatively, providing early evidence that semantic knowledge has an underlying low-dimensional organization rather than being an unstructured collection of discrete symbols.







