### How do LLMs learn word meaning

Before diving into our computational model for meaning, let's take a quick glimpse at the algorithms behind Large Language Models (LLMs). Then, we will compare the LLM approach with the one we are going to design, so you can decide which offers a more intuitive understanding of language meaning.

## Big Question

How can a machine learn the meaning of words without a dictionary?

Although large language models can use words in remarkably fluent and appropriate ways, they do not recognize word meaning in the same way that human beings do.

- For humans, word meaning is grounded in $\color{red}{\text{perception, action, and lived experience}}$ : we learn what ''apple'' means by seeing, touching, tasting, and interacting with apples in the world.
- An LLM never perceives or interacts with the world directly. It learns entirely from $\color{red}{\text{textual patterns}}$ , discovering how words co-occur with other words across massive datasets.

As a result, an LLMâ€™s ''understanding'' of a word consists in a statistical representation of its linguistic contexts, not in a concept tied to sensory experience, intentions, or beliefs. In this sense, LLMs model how words are used, not what words are.



